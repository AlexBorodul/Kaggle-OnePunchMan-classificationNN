{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import os\n",
    "import albumentations as A\n",
    "import csv\n",
    "\n",
    "train_data_dir = '.\\\\train\\\\train'\n",
    "classes = ['Гароу', 'Генос', 'Сайтама', 'Соник', 'Татсумаки', 'Фубуки']\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, ), (0.5, ))\n",
    "    ])\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        for idx, cls in enumerate(classes):\n",
    "            cls_dir = os.path.join(data_dir, cls)\n",
    "            for img_name in os.listdir(cls_dir):\n",
    "                self.images.append(os.path.join(cls_dir, img_name))\n",
    "                self.labels.append(idx)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "train_dataset = ImageDataset(train_data_dir, transform=transform)\n",
    "\n",
    "train_loader =  DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(self.resnet.layer4[2].conv3.out_channels, len(classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 1, Потери: 1.51135\n",
      "Эпоха: 2, Потери: 0.30359\n",
      "Эпоха: 3, Потери: 0.17321\n",
      "Эпоха: 4, Потери: 0.11787\n",
      "Эпоха: 5, Потери: 0.03740\n",
      "Эпоха: 6, Потери: 0.01767\n",
      "Эпоха: 7, Потери: 0.05788\n",
      "Эпоха: 8, Потери: 0.16332\n",
      "Эпоха: 9, Потери: 0.19709\n",
      "Эпоха: 10, Потери: 0.09322\n"
     ]
    }
   ],
   "source": [
    "model = Net(classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "for ep in range(num_epochs):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "    for img, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(img)\n",
    "        losses = criterion(out, label)\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        loss += losses.item()\n",
    "    print(f\"Эпоха: {ep+1}, Потери: {loss/len(train_loader):.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_path = \"./test/test\"\n",
    "preds = []\n",
    "images = []\n",
    "\n",
    "# Записываем результаты предсказаний\n",
    "for image_path in os.listdir(test_path):\n",
    "    image = Image.open(os.path.join(test_path, image_path)).convert('RGB')\n",
    "    image_tensor = preprocess(image)\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "    images.append(image_path)\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        preds.append(predicted.item())\n",
    "\n",
    "\n",
    "labels = ['Гароу', 'Генос', 'Сайтама', 'Соник', 'Татсумаки', 'Фубуки']\n",
    "with open('submissiom.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['id', 'path', 'class']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(preds)):\n",
    "        writer.writerow({'id': i, 'path': images[i], 'class': labels[preds[i]]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
